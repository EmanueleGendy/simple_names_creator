{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "78307286-9a46-424a-8e60-da770f5cda8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt  # for making figures\n",
    "%matplotlib inline\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca04eab2-c1da-4eb8-80d8-857c8bc037b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the list of words from a text file\n",
    "words = open('names.txt', 'r').read().splitlines()\n",
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s: i + 1 for i, s in enumerate(chars)}\n",
    "stoi['.'] = 0  # Map the '.' character to 0\n",
    "itos = {i: s for s, i in stoi.items()}\n",
    "vocab_size = len(itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "02440345-99e2-4789-a1e0-f97edb7b4cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182625, 8]) torch.Size([182625])\n",
      "torch.Size([22655, 8]) torch.Size([22655])\n",
      "torch.Size([22866, 8]) torch.Size([22866])\n"
     ]
    }
   ],
   "source": [
    "block_size = 8  # Context length# Build the vocabulary of characters and mappings to/from integers\n",
    "\n",
    "\n",
    "# Function to build the dataset\n",
    "def build_dataset(words):\n",
    "    \n",
    "    X, Y = [], []\n",
    "\n",
    "    for w in words:\n",
    "        context = [0] * block_size  # Initialize the context with zeros\n",
    "        for ch in w + '.':  # Iterate over the word and an end token\n",
    "            ix = stoi[ch]  # Get the integer mapping of the character\n",
    "            X.append(context)  # Append the current context to X\n",
    "            Y.append(ix)  # Append the current character's index to Y\n",
    "            # Update the context\n",
    "            context = context[1:] + [ix]\n",
    "\n",
    "    X = torch.tensor(X)\n",
    "    Y = torch.tensor(Y)\n",
    "    print(X.shape, Y.shape)\n",
    "    return X, Y\n",
    "\n",
    "# Shuffle and split the dataset\n",
    "random.seed(42)\n",
    "random.shuffle(words)\n",
    "n1 = int(0.8 * len(words))\n",
    "n2 = int(0.9 * len(words))\n",
    "\n",
    "Xtr, Ytr = build_dataset(words[:n1])  # Training set\n",
    "Xdev, Ydev = build_dataset(words[n1:n2])  # Development set\n",
    "Xte, Yte = build_dataset(words[n2:])  # Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf04f69f-eb65-4cb0-b84c-0687b285612b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "........ ----> y\n",
      ".......y ----> u\n",
      "......yu ----> h\n",
      ".....yuh ----> e\n",
      "....yuhe ----> n\n",
      "...yuhen ----> g\n",
      "..yuheng ----> .\n",
      "........ ----> d\n",
      ".......d ----> i\n",
      "......di ----> o\n",
      ".....dio ----> n\n",
      "....dion ----> d\n",
      "...diond ----> r\n",
      "..diondr ----> e\n",
      ".diondre ----> .\n",
      "........ ----> x\n",
      ".......x ----> a\n",
      "......xa ----> v\n",
      ".....xav ----> i\n",
      "....xavi ----> e\n"
     ]
    }
   ],
   "source": [
    "for x,y in zip(Xtr[:20], Ytr[:20]):\n",
    "    print(''.join(itos[ix.item()] for ix in x), '---->', itos[y.item()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "66b91559-06c5-4143-8dbc-e9cbf4debdc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Near copy paste of the layers we have developed in Part 3\n",
    "\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "class Linear:\n",
    "  \n",
    "    def __init__(self, fan_in, fan_out, bias=True):\n",
    "        self.weight = torch.randn((fan_in, fan_out)) / fan_in**0.5 # note: kaiming init\n",
    "        self.bias = torch.zeros(fan_out) if bias else None\n",
    "  \n",
    "    def __call__(self, x):\n",
    "        self.out = x @ self.weight\n",
    "        if self.bias is not None:\n",
    "            self.out += self.bias\n",
    "        return self.out\n",
    "  \n",
    "    def parameters(self):\n",
    "        return [self.weight] + ([] if self.bias is None else [self.bias])\n",
    "\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "class BatchNorm1d:\n",
    "  \n",
    "    def __init__(self, dim, eps=1e-5, momentum=0.1):\n",
    "        self.eps = eps\n",
    "        self.momentum = momentum\n",
    "        self.training = True\n",
    "        # parameters (trained with backprop)\n",
    "        self.gamma = torch.ones(dim)\n",
    "        self.beta = torch.zeros(dim)\n",
    "        # buffers (trained with a running 'momentum update')\n",
    "        self.running_mean = torch.zeros(dim)\n",
    "        self.running_var = torch.ones(dim)\n",
    "  \n",
    "    def __call__(self, x):\n",
    "        # calculate the forward pass\n",
    "        if self.training:\n",
    "            if x.ndim == 2:\n",
    "                dim = 0\n",
    "            elif x.ndim == 3:\n",
    "                dim = (0,1)\n",
    "            xmean = x.mean(dim, keepdim=True) # batch mean\n",
    "            xvar = x.var(dim, keepdim=True) # batch variance\n",
    "        else:\n",
    "            xmean = self.running_mean\n",
    "            xvar = self.running_var\n",
    "        xhat = (x - xmean) / torch.sqrt(xvar + self.eps) # normalize to unit variance\n",
    "        self.out = self.gamma * xhat + self.beta\n",
    "        # update the buffers\n",
    "        if self.training:\n",
    "            with torch.no_grad():\n",
    "                self.running_mean = (1 - self.momentum) * self.running_mean + self.momentum * xmean\n",
    "                self.running_var = (1 - self.momentum) * self.running_var + self.momentum * xvar\n",
    "        return self.out\n",
    "\n",
    "    def parameters(self):\n",
    "        return [self.gamma, self.beta]\n",
    "\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "class Tanh:\n",
    "    def __call__(self, x):\n",
    "        self.out = torch.tanh(x)\n",
    "        return self.out\n",
    "    def parameters(self):\n",
    "        return []\n",
    "\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "class Embedding:\n",
    "  \n",
    "    def __init__(self, num_embeddings, embedding_dim):\n",
    "        self.weight = torch.randn((num_embeddings, embedding_dim))\n",
    "    \n",
    "    def __call__(self, IX):\n",
    "        self.out = self.weight[IX]\n",
    "        return self.out\n",
    "  \n",
    "    def parameters(self):\n",
    "        return [self.weight]\n",
    "\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "class FlattenConsecutive:\n",
    "  \n",
    "    def __init__(self, n):\n",
    "        self.n = n\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        B, T, C = x.shape\n",
    "        x = x.view(B, T//self.n, C*self.n)\n",
    "        if x.shape[1] == 1:\n",
    "            x = x.squeeze(1)\n",
    "        self.out = x\n",
    "        return self.out\n",
    "  \n",
    "    def parameters(self):\n",
    "        return []\n",
    "\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "class Sequential:\n",
    "  \n",
    "    def __init__(self, layers):\n",
    "        self.layers = layers\n",
    "  \n",
    "    def __call__(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        self.out = x\n",
    "        return self.out\n",
    "  \n",
    "\n",
    "\n",
    "    def parameters(self):\n",
    "    # get parameters of all layers and stretch them out into one list\n",
    "        return [p for layer in self.layers for p in layer.parameters()]    \n",
    "    \n",
    "    \n",
    "torch.manual_seed(42); # seed rng for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "92fc7419-5643-4abd-9a08-c66777dd940b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170897\n"
     ]
    }
   ],
   "source": [
    "n_embd = 10 # the dimensionality of the character embedding vectors\n",
    "n_hidden = 200 # the number of neurons in the hidden layer of the MLP\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential([\n",
    "    Embedding(vocab_size,n_embd),\n",
    "    FlattenConsecutive(2),Linear(n_embd * 2, n_hidden, bias = False), BatchNorm1d(n_hidden), Tanh(),\n",
    "    FlattenConsecutive(2),Linear(n_hidden * 2, n_hidden, bias = False), BatchNorm1d(n_hidden), Tanh(),\n",
    "    FlattenConsecutive(2),Linear(n_hidden * 2, n_hidden, bias = False), BatchNorm1d(n_hidden), Tanh(),\n",
    "    Linear(n_hidden,vocab_size),\n",
    "])\n",
    "\n",
    "#parameters initialization\n",
    "with torch.no_grad():\n",
    "    model.layers[-1].weight *= 0.1\n",
    "    \n",
    "    \n",
    "parameters = model.parameters()\n",
    "print(sum(p.nelement() for p in parameters)) # number of parameters in total\n",
    "for p in parameters:\n",
    "    p.requires_grad = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0caf0694-defd-4ee5-9278-2ffb6fc0369d",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Embedding' object has no attribute 'out'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-7a3222fc407d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m':'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Embedding' object has no attribute 'out'"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    print(layer.__class__.__name__,':',tuple(layer.out.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e8d2e968-d229-4226-94e1-d8d327ddd29a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76579\n"
     ]
    }
   ],
   "source": [
    "# original network\n",
    "# n_embd = 10 # the dimensionality of the character embedding vectors\n",
    "# n_hidden = 300 # the number of neurons in the hidden layer of the MLP\n",
    "# model = Sequential([\n",
    "#   Embedding(vocab_size, n_embd),\n",
    "#   FlattenConsecutive(8), Linear(n_embd * 8, n_hidden, bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
    "#   Linear(n_hidden, vocab_size),\n",
    "# ])\n",
    "\n",
    "# hierarchical network\n",
    "n_embd = 24 # the dimensionality of the character embedding vectors\n",
    "n_hidden = 128 # the number of neurons in the hidden layer of the MLP\n",
    "model = Sequential([\n",
    "  Embedding(vocab_size, n_embd),\n",
    "  FlattenConsecutive(2), Linear(n_embd * 2, n_hidden, bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
    "  FlattenConsecutive(2), Linear(n_hidden*2, n_hidden, bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
    "  FlattenConsecutive(2), Linear(n_hidden*2, n_hidden, bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
    "  Linear(n_hidden, vocab_size),\n",
    "])\n",
    "\n",
    "# parameter init\n",
    "with torch.no_grad():\n",
    "    model.layers[-1].weight *= 0.1 # last layer make less confident\n",
    "\n",
    "parameters = model.parameters()\n",
    "print(sum(p.nelement() for p in parameters)) # number of parameters in total\n",
    "for p in parameters:\n",
    "    p.requires_grad = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ce6d3e91-6d96-4c13-9fa4-7067b6303ba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0/ 200000: 3.2874\n",
      "  10000/ 200000: 2.2921\n",
      "  20000/ 200000: 1.9586\n",
      "  30000/ 200000: 1.6836\n",
      "  40000/ 200000: 2.0732\n",
      "  50000/ 200000: 2.3158\n",
      "  60000/ 200000: 2.0437\n",
      "  70000/ 200000: 1.9671\n",
      "  80000/ 200000: 1.9087\n",
      "  90000/ 200000: 2.0358\n",
      " 100000/ 200000: 2.0136\n",
      " 110000/ 200000: 2.1904\n",
      " 120000/ 200000: 2.5270\n",
      " 130000/ 200000: 1.9153\n",
      " 140000/ 200000: 1.9959\n",
      " 150000/ 200000: 1.9714\n",
      " 160000/ 200000: 2.1516\n",
      " 170000/ 200000: 1.9072\n",
      " 180000/ 200000: 2.0227\n",
      " 190000/ 200000: 1.7282\n"
     ]
    }
   ],
   "source": [
    "# same optimization as last time\n",
    "max_steps = 200000\n",
    "batch_size = 32\n",
    "lossi = []\n",
    "\n",
    "for i in range(max_steps):\n",
    "  \n",
    "  # minibatch construct\n",
    "  ix = torch.randint(0, Xtr.shape[0], (batch_size,))\n",
    "  Xb, Yb = Xtr[ix], Ytr[ix] # batch X,Y\n",
    "  \n",
    "  # forward pass\n",
    "  logits = model(Xb)\n",
    "  loss = F.cross_entropy(logits, Yb) # loss function\n",
    "  \n",
    "  # backward pass\n",
    "  for p in parameters:\n",
    "    p.grad = None\n",
    "  loss.backward()\n",
    "  \n",
    "  # update: simple SGD\n",
    "  lr = 0.1 if i < 150000 else 0.01 # step learning rate decay\n",
    "  for p in parameters:\n",
    "    p.data += -lr * p.grad\n",
    "\n",
    "  # track stats\n",
    "  if i % 10000 == 0: # print every once in a while\n",
    "    print(f'{i:7d}/{max_steps:7d}: {loss.item():.4f}')\n",
    "  lossi.append(loss.log10().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1ca454bc-cc19-48aa-95e4-f57b68e9f439",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fa67ab4f8e0>]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(torch.tensor(lossi).view(-1, 1000).mean(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3d6f0e17-6d36-4788-b9b7-8e03da7efffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# put layers into eval mode (needed for batchnorm especially)\n",
    "for layer in model.layers:\n",
    "    layer.training = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c48aed5f-9972-4671-aaed-1663a055078e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 1.7676647901535034\n",
      "val 1.9967879056930542\n"
     ]
    }
   ],
   "source": [
    "# evaluate the loss\n",
    "@torch.no_grad() # this decorator disables gradient tracking inside pytorch\n",
    "def split_loss(split):\n",
    "    x,y = {\n",
    "        'train': (Xtr, Ytr),\n",
    "        'val': (Xdev, Ydev),\n",
    "        'test': (Xte, Yte),\n",
    "    }[split]\n",
    "    logits = model(x)\n",
    "    loss = F.cross_entropy(logits, y)\n",
    "    print(split, loss.item())\n",
    "\n",
    "split_loss('train')\n",
    "split_loss('val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b1930b90-9d67-4df6-9748-26cec9da142e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plawd.\n",
      "airah.\n",
      "rayaan.\n",
      "ditcael.\n",
      "brayley.\n",
      "decori.\n",
      "luxi.\n",
      "emmarie.\n",
      "jorda.\n",
      "jaxsus.\n",
      "aizaanna.\n",
      "cedrick.\n",
      "katiann.\n",
      "chi.\n",
      "hayden.\n",
      "leanna.\n",
      "marcia.\n",
      "alexus.\n",
      "kameia.\n",
      "dilyn.\n"
     ]
    }
   ],
   "source": [
    "# sample from the model\n",
    "for _ in range(20):\n",
    "    \n",
    "    out = []\n",
    "    context = [0] * block_size # initialize with all ...\n",
    "    while True:\n",
    "      # forward pass the neural net\n",
    "      logits = model(torch.tensor([context]))\n",
    "      probs = F.softmax(logits, dim=1)\n",
    "      # sample from the distribution\n",
    "      ix = torch.multinomial(probs, num_samples=1).item()\n",
    "      # shift the context window and track the samples\n",
    "      context = context[1:] + [ix]\n",
    "      out.append(ix)\n",
    "      # if we sample the special '.' token, break\n",
    "      if ix == 0:\n",
    "        break\n",
    "    \n",
    "    print(''.join(itos[i] for i in out)) # decode and print the generated word\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a16660-db87-4420-9f12-f29b2c6262ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
